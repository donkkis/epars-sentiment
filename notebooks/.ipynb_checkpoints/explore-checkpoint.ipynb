{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "south-empire",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "Load and check data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "judicial-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "auburn-prevention",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The results in 2nd line treatment show an ORR ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The long duration of response and high durable...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The median OS time in the updated results exce...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Therefore, the clinical benefit in 2nd line tr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The data provided in 1st line, although prelim...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           Sentence  Positive  Negative  \\\n",
       "0   1  The results in 2nd line treatment show an ORR ...         1         0   \n",
       "1   2  The long duration of response and high durable...         1         0   \n",
       "2   3  The median OS time in the updated results exce...         0         0   \n",
       "3   4  Therefore, the clinical benefit in 2nd line tr...         1         0   \n",
       "4   5  The data provided in 1st line, although prelim...         1         0   \n",
       "\n",
       "   Neutral  \n",
       "0        0  \n",
       "1        0  \n",
       "2        1  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('../data/sentences_with_sentiment.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "varied-placement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-stopping",
   "metadata": {},
   "source": [
    "Drop the ID column since it contains no useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gentle-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-prompt",
   "metadata": {},
   "source": [
    "Labels seem to be already one-hot encoded. Let's ensure the encoding is valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collect-postcard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(data.loc[:, ['Positive', 'Negative', 'Neutral']].sum(axis=1) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-tracy",
   "metadata": {},
   "source": [
    "Check ```Sentence``` column for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "radio-restaurant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19     True\n",
       "134    True\n",
       "136    True\n",
       "137    True\n",
       "138    True\n",
       "139    True\n",
       "140    True\n",
       "141    True\n",
       "142    True\n",
       "143    True\n",
       "144    True\n",
       "146    True\n",
       "147    True\n",
       "148    True\n",
       "149    True\n",
       "150    True\n",
       "151    True\n",
       "152    True\n",
       "153    True\n",
       "154    True\n",
       "155    True\n",
       "157    True\n",
       "158    True\n",
       "159    True\n",
       "160    True\n",
       "161    True\n",
       "162    True\n",
       "163    True\n",
       "164    True\n",
       "165    True\n",
       "Name: Sentence, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 300)\n",
    "dup = data['Sentence'].duplicated()\n",
    "dup[dup]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-commitment",
   "metadata": {},
   "source": [
    "Are the same rows also duplicates when considering also the labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "therapeutic-cornell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19     True\n",
       "134    True\n",
       "136    True\n",
       "137    True\n",
       "138    True\n",
       "139    True\n",
       "140    True\n",
       "141    True\n",
       "142    True\n",
       "143    True\n",
       "144    True\n",
       "146    True\n",
       "147    True\n",
       "148    True\n",
       "149    True\n",
       "150    True\n",
       "151    True\n",
       "152    True\n",
       "153    True\n",
       "154    True\n",
       "155    True\n",
       "157    True\n",
       "158    True\n",
       "159    True\n",
       "160    True\n",
       "161    True\n",
       "162    True\n",
       "163    True\n",
       "164    True\n",
       "165    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_labels = data[['Sentence', 'Positive', 'Negative', 'Neutral']].duplicated()\n",
    "dup_labels[dup_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ethical-heart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(dup[dup].index == dup_labels[dup_labels].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-celebration",
   "metadata": {},
   "source": [
    "Yes, it would seem so. In principle duplicated sentences could be used to represent opinions given by different experts, but since also the labels are the same this would not seem to be the case judging from this sample. At this stage we'll consider it safe to discard the duplicated rows since they seem to bring no obvious value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "facial-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(dup[dup].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accessible-rolling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "meaning-supply",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The results in 2nd line treatment show an ORR ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The long duration of response and high durable...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The median OS time in the updated results exce...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Therefore, the clinical benefit in 2nd line tr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The data provided in 1st line, although prelim...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Positive  Negative  \\\n",
       "0  The results in 2nd line treatment show an ORR ...         1         0   \n",
       "1  The long duration of response and high durable...         1         0   \n",
       "2  The median OS time in the updated results exce...         0         0   \n",
       "3  Therefore, the clinical benefit in 2nd line tr...         1         0   \n",
       "4  The data provided in 1st line, although prelim...         1         0   \n",
       "\n",
       "   Neutral  \n",
       "0        0  \n",
       "1        0  \n",
       "2        1  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-mobile",
   "metadata": {},
   "source": [
    "Now we can check the label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "elder-limitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples 140\n",
      "Negative samples 32\n",
      "Neutral samples 64\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples', len(data[data['Positive'] == 1]))\n",
    "print('Negative samples', len(data[data['Negative'] == 1]))\n",
    "print('Neutral samples', len(data[data['Neutral'] == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-trader",
   "metadata": {},
   "source": [
    "The class distribution is clearly skewed towards positive sentiment. In addition, quite significant portion are neutral - this could be problematic since classifiers will probably have a hard time figuring out subtle differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-verse",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-jungle",
   "metadata": {},
   "source": [
    "Let's try to grasp some intuition behind data by listing out the most common words. The process involves building corpora of the sentences representing the three labels, filtering out knwon English language stop words and punctation, and finally counting the Frequency distributions amongst the indivudual corpora as well as the composite corpus. Throughout this process the excellent nltk library is utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "racial-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-memorabilia",
   "metadata": {},
   "source": [
    "Start by creating the corpora of Positive, Negative and Neutral labels respectively and tokenizing those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "suffering-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_pos = word_tokenize(' '.join(data.loc[data['Positive'] == 1, 'Sentence']).lower())\n",
    "corp_neg = word_tokenize(' '.join(data.loc[data['Negative'] == 1, 'Sentence']).lower())\n",
    "corp_neutr = word_tokenize(' '.join(data.loc[data['Neutral'] == 1, 'Sentence']).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "injured-offer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'results',\n",
       " 'in',\n",
       " '2nd',\n",
       " 'line',\n",
       " 'treatment',\n",
       " 'show',\n",
       " 'an',\n",
       " 'orr',\n",
       " 'of',\n",
       " '33',\n",
       " '%',\n",
       " 'with',\n",
       " 'some',\n",
       " 'patients']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp_pos[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-sensitivity",
   "metadata": {},
   "source": [
    "Filter out known stopwords. Notice that before this operation stopwords need to be downloaded using:\n",
    "\n",
    "```\n",
    ">>> import nltk\n",
    ">>> nltk.download('stopwords')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "appointed-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_pos = [t for t in corp_pos if t not in stopwords.words('english')]\n",
    "corp_neg = [t for t in corp_neg if t not in stopwords.words('english')]\n",
    "corp_neutr = [t for t in corp_neutr if t not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-mailman",
   "metadata": {},
   "source": [
    "Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "activated-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_pos = [t for t in corp_pos if t not in string.punctuation]\n",
    "corp_neg = [t for t in corp_neg if t not in string.punctuation]\n",
    "corp_neutr = [t for t in corp_neutr if t not in string.punctuation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-illness",
   "metadata": {},
   "source": [
    "Then check out the freqdists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "numerical-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_pos = FreqDist(corp_pos)\n",
    "fd_neg = FreqDist(corp_neg)\n",
    "fd_neutr = FreqDist(corp_neutr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "interior-funeral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('safety', 41),\n",
       " ('data', 39),\n",
       " ('study', 29),\n",
       " ('clinical', 27),\n",
       " ('patients', 25),\n",
       " ('efficacy', 23),\n",
       " ('treatment', 22),\n",
       " ('considered', 21),\n",
       " ('profile', 19),\n",
       " ('product', 17),\n",
       " ('bioequivalence', 15),\n",
       " ('studies', 14),\n",
       " ('support', 14),\n",
       " ('overall', 14),\n",
       " ('subjects', 14),\n",
       " ('sma', 14),\n",
       " ('results', 12),\n",
       " ('application', 12),\n",
       " ('mg', 12),\n",
       " ('rate', 11)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_pos.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "strong-storm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('safety', 14),\n",
       " ('data', 11),\n",
       " ('patients', 9),\n",
       " ('study', 8),\n",
       " ('treatment', 7),\n",
       " ('period', 6),\n",
       " ('studies', 6),\n",
       " ('combination', 6),\n",
       " ('chmp', 5),\n",
       " ('address', 5),\n",
       " ('efficacy', 5),\n",
       " ('limited', 5),\n",
       " ('considers', 4),\n",
       " ('following', 4),\n",
       " ('measures', 4),\n",
       " ('necessary', 4),\n",
       " ('additional', 4),\n",
       " ('related', 4),\n",
       " ('provided', 4),\n",
       " ('term', 4)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_neg.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "institutional-polymer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('studies', 19),\n",
       " ('study', 15),\n",
       " ('safety', 13),\n",
       " ('efficacy', 11),\n",
       " ('patients', 10),\n",
       " ('dose', 10),\n",
       " ('insulin', 10),\n",
       " ('data', 9),\n",
       " ('difference', 8),\n",
       " ('clinical', 8),\n",
       " ('product', 7),\n",
       " ('additional', 7),\n",
       " ('compared', 7),\n",
       " ('frc', 7),\n",
       " ('infections', 6),\n",
       " ('glargine', 6),\n",
       " ('lixisenatide', 6),\n",
       " ('provided', 5),\n",
       " ('related', 5),\n",
       " ('reactions', 5)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_neutr.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-society",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
