{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "south-empire",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "Load and check data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "judicial-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "auburn-prevention",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The results in 2nd line treatment show an ORR ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The long duration of response and high durable...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The median OS time in the updated results exce...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Therefore, the clinical benefit in 2nd line tr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The data provided in 1st line, although prelim...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           Sentence  Positive  Negative  \\\n",
       "0   1  The results in 2nd line treatment show an ORR ...         1         0   \n",
       "1   2  The long duration of response and high durable...         1         0   \n",
       "2   3  The median OS time in the updated results exce...         0         0   \n",
       "3   4  Therefore, the clinical benefit in 2nd line tr...         1         0   \n",
       "4   5  The data provided in 1st line, although prelim...         1         0   \n",
       "\n",
       "   Neutral  \n",
       "0        0  \n",
       "1        0  \n",
       "2        1  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('../data/sentences_with_sentiment.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "varied-placement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-stopping",
   "metadata": {},
   "source": [
    "Drop the ID column since it contains no useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gentle-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-prompt",
   "metadata": {},
   "source": [
    "Labels seem to be already one-hot encoded. Let's ensure the encoding is valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collect-postcard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(data.loc[:, ['Positive', 'Negative', 'Neutral']].sum(axis=1) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-tracy",
   "metadata": {},
   "source": [
    "Check ```Sentence``` column for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "radio-restaurant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19     True\n",
       "134    True\n",
       "136    True\n",
       "137    True\n",
       "138    True\n",
       "139    True\n",
       "140    True\n",
       "141    True\n",
       "142    True\n",
       "143    True\n",
       "144    True\n",
       "146    True\n",
       "147    True\n",
       "148    True\n",
       "149    True\n",
       "150    True\n",
       "151    True\n",
       "152    True\n",
       "153    True\n",
       "154    True\n",
       "155    True\n",
       "157    True\n",
       "158    True\n",
       "159    True\n",
       "160    True\n",
       "161    True\n",
       "162    True\n",
       "163    True\n",
       "164    True\n",
       "165    True\n",
       "Name: Sentence, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 300)\n",
    "dup = data['Sentence'].duplicated()\n",
    "dup[dup]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-commitment",
   "metadata": {},
   "source": [
    "Are the same rows also duplicates when considering also the labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "therapeutic-cornell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19     True\n",
       "134    True\n",
       "136    True\n",
       "137    True\n",
       "138    True\n",
       "139    True\n",
       "140    True\n",
       "141    True\n",
       "142    True\n",
       "143    True\n",
       "144    True\n",
       "146    True\n",
       "147    True\n",
       "148    True\n",
       "149    True\n",
       "150    True\n",
       "151    True\n",
       "152    True\n",
       "153    True\n",
       "154    True\n",
       "155    True\n",
       "157    True\n",
       "158    True\n",
       "159    True\n",
       "160    True\n",
       "161    True\n",
       "162    True\n",
       "163    True\n",
       "164    True\n",
       "165    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_labels = data[['Sentence', 'Positive', 'Negative', 'Neutral']].duplicated()\n",
    "dup_labels[dup_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ethical-heart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(dup[dup].index == dup_labels[dup_labels].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-celebration",
   "metadata": {},
   "source": [
    "Yes, it would seem so. \n",
    "\n",
    "In principle duplicated sentences could be used to represent opinions given by different experts, but since also the labels are the same this would not seem to be the case judging from this sample. The more likely explanation is that each duplicated value representes a common phrase that is _actually_ duplicated across various samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-mobile",
   "metadata": {},
   "source": [
    "Now we can check the label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "elder-limitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples 160\n",
      "Negative samples 36\n",
      "Neutral samples 70\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples', len(data[data['Positive'] == 1]))\n",
    "print('Negative samples', len(data[data['Negative'] == 1]))\n",
    "print('Neutral samples', len(data[data['Neutral'] == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-trader",
   "metadata": {},
   "source": [
    "The class distribution is clearly skewed towards positive sentiment. In addition, quite significant portion are neutral - this could be problematic since classifiers will probably have a hard time figuring out subtle differences.\n",
    "\n",
    "While were at it, lets produce a quick naive baseline for classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "intelligent-invasion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6015037593984962"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['Positive'] == 1]) / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-lloyd",
   "metadata": {},
   "source": [
    "By simply using the largest class as a prediction each time, we should expect on average 60 % accuracy (non-weighted). Any further classifiers should aim to at least outperform this metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-theorem",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-diagnosis",
   "metadata": {},
   "source": [
    "### Unigram frequency analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-mentor",
   "metadata": {},
   "source": [
    "Let's try to grasp some intuition behind data by listing out the most common words. The process involves building corpora of the sentences representing the three labels, filtering out knwon English language stop words and punctation, and finally counting the Frequency distributions amongst the indivudual corpora as well as the composite corpus. Throughout this process the excellent nltk library is utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "welsh-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-pixel",
   "metadata": {},
   "source": [
    "Start by creating the corpora of Positive, Negative and Neutral labels respectively and tokenizing those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "artificial-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_pos = word_tokenize(' '.join(data.loc[data['Positive'] == 1, 'Sentence']).lower())\n",
    "corp_neg = word_tokenize(' '.join(data.loc[data['Negative'] == 1, 'Sentence']).lower())\n",
    "corp_neutr = word_tokenize(' '.join(data.loc[data['Neutral'] == 1, 'Sentence']).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "active-butter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'results',\n",
       " 'in',\n",
       " '2nd',\n",
       " 'line',\n",
       " 'treatment',\n",
       " 'show',\n",
       " 'an',\n",
       " 'orr',\n",
       " 'of',\n",
       " '33',\n",
       " '%',\n",
       " 'with',\n",
       " 'some',\n",
       " 'patients']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp_pos[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-savannah",
   "metadata": {},
   "source": [
    "Filter out known stopwords. Notice that before this operation stopwords need to be downloaded using:\n",
    "\n",
    "```\n",
    ">>> import nltk\n",
    ">>> nltk.download('stopwords')\n",
    "```\n",
    "\n",
    "Then, a basis for a stop word list can be gotten from ```nltk.corpus.stopwords.words('english')```. Below, we will further tweak this basis list, in a attempt to reduce the noice present by meaningless words such as 'a', 'the', 'it' etc while still keeping acceptable discriminitive power between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "formed-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = [\n",
    "    'i',\n",
    "    'me',\n",
    "    'my',\n",
    "    'myself',\n",
    "    'we',\n",
    "    'our',\n",
    "    'ours',\n",
    "    'ourselves',\n",
    "    'you',\n",
    "    \"you're\",\n",
    "    \"you've\",\n",
    "    \"you'll\",\n",
    "    \"you'd\",\n",
    "    'your',\n",
    "    'yours',\n",
    "    'yourself',\n",
    "    'yourselves',\n",
    "    'he',\n",
    "    'him',\n",
    "    'his',\n",
    "    'himself',\n",
    "    'she',\n",
    "    \"she's\",\n",
    "    'her',\n",
    "    'hers',\n",
    "    'herself',\n",
    "    'it',\n",
    "    \"it's\",\n",
    "    'its',\n",
    "    'itself',\n",
    "    'they',\n",
    "    'them',\n",
    "    'their',\n",
    "    'theirs',\n",
    "    'themselves',\n",
    "    'what',\n",
    "    'which',\n",
    "    'who',\n",
    "    'whom',\n",
    "    'this',\n",
    "    'that',\n",
    "    \"that'll\",\n",
    "    'these',\n",
    "    'those',\n",
    "    'am',\n",
    "    'is',\n",
    "    'are',\n",
    "    'was',\n",
    "    'were',\n",
    "    'be',\n",
    "    'been',\n",
    "    'being',\n",
    "    'have',\n",
    "    'has',\n",
    "    'had',\n",
    "    'having',\n",
    "    'do',\n",
    "    'does',\n",
    "    'did',\n",
    "    'doing',\n",
    "    'a',\n",
    "    'an',\n",
    "    'the',\n",
    "    'and',\n",
    "    'but',\n",
    "    'if',\n",
    "    'or',\n",
    "    'as',\n",
    "    'of',\n",
    "    'at',\n",
    "    'by',\n",
    "    'for',\n",
    "    'with',\n",
    "    'about',\n",
    "    'into',\n",
    "    'through',\n",
    "    'during',\n",
    "    'to',\n",
    "    'from',\n",
    "    'in',\n",
    "    'out',\n",
    "    'on',\n",
    "    'off',\n",
    "    'then',\n",
    "    'once',\n",
    "    'here',\n",
    "    'there',\n",
    "    'when',\n",
    "    'where',\n",
    "    'why',\n",
    "    'how',\n",
    "    'both',\n",
    "    'each',\n",
    "    'other',\n",
    "    'such',\n",
    "    'own',\n",
    "    'so',\n",
    "    's',\n",
    "    't',\n",
    "    'can',\n",
    "    'will',\n",
    "    'just',\n",
    "    'now',\n",
    "    'd',\n",
    "    'll',\n",
    "    'm',\n",
    "    'o',\n",
    "    're',\n",
    "    've',\n",
    "    'y',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "statewide-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_pos = [t for t in corp_pos if t not in sw]\n",
    "corp_neg = [t for t in corp_neg if t not in sw]\n",
    "corp_neutr = [t for t in corp_neutr if t not in sw]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-seafood",
   "metadata": {},
   "source": [
    "Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "exceptional-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_pos = [t for t in corp_pos if t not in string.punctuation]\n",
    "corp_neg = [t for t in corp_neg if t not in string.punctuation]\n",
    "corp_neutr = [t for t in corp_neutr if t not in string.punctuation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-christianity",
   "metadata": {},
   "source": [
    "Then check out the freqdists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "united-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_pos = FreqDist(corp_pos)\n",
    "fd_neg = FreqDist(corp_neg)\n",
    "fd_neutr = FreqDist(corp_neutr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hired-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten = pd.DataFrame({\n",
    "    'Positive': [w[0] for w in fd_pos.most_common(10)],\n",
    "    'Pos_rate': [w[1] / len(data[data['Positive'] == 1]) for w in fd_pos.most_common(10)],\n",
    "    'Negative': [w[0] for w in fd_neg.most_common(10)],\n",
    "    'Neg_rate': [w[1] / len(data[data['Negative'] == 1]) for w in fd_neg.most_common(10)],    \n",
    "    'Neutral': [w[0] for w in fd_neutr.most_common(10)],\n",
    "    'Neutr_rate': [w[1] / len(data[data['Neutral'] == 1])for w in fd_neutr.most_common(10)]\n",
    "}, index=range(1,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "capital-pillow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive</th>\n",
       "      <th>Pos_rate</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neg_rate</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Neutr_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>safety</td>\n",
       "      <td>0.29375</td>\n",
       "      <td>safety</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>studies</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data</td>\n",
       "      <td>0.28125</td>\n",
       "      <td>data</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>safety</td>\n",
       "      <td>0.242857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>study</td>\n",
       "      <td>0.20625</td>\n",
       "      <td>patients</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>study</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>efficacy</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>study</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>ct-p10</td>\n",
       "      <td>0.171429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clinical</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>should</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>efficacy</td>\n",
       "      <td>0.157143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>patients</td>\n",
       "      <td>0.16875</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>data</td>\n",
       "      <td>0.157143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>considered</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>limited</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>patients</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>treatment</td>\n",
       "      <td>0.15000</td>\n",
       "      <td>further</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>dose</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>profile</td>\n",
       "      <td>0.14375</td>\n",
       "      <td>address</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>insulin</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>product</td>\n",
       "      <td>0.13125</td>\n",
       "      <td>efficacy</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>product</td>\n",
       "      <td>0.128571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Positive  Pos_rate   Negative  Neg_rate   Neutral  Neutr_rate\n",
       "1       safety   0.29375     safety  0.472222   studies    0.300000\n",
       "2         data   0.28125       data  0.388889    safety    0.242857\n",
       "3        study   0.20625   patients  0.333333     study    0.214286\n",
       "4     efficacy   0.18750      study  0.250000    ct-p10    0.171429\n",
       "5     clinical   0.17500     should  0.222222  efficacy    0.157143\n",
       "6     patients   0.16875  treatment  0.194444      data    0.157143\n",
       "7   considered   0.16250    limited  0.194444  patients    0.142857\n",
       "8    treatment   0.15000    further  0.166667      dose    0.142857\n",
       "9      profile   0.14375    address  0.166667   insulin    0.142857\n",
       "10     product   0.13125   efficacy  0.166667   product    0.128571"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-screw",
   "metadata": {},
   "source": [
    "'Safety' and 'data' seem to be very popular words amongst both Positive and Negative corpora, although the proportions in the negative case are significantly higher. Words like 'should', 'further', 'limited' seem like obvious predictors for the negative class. In neutral class the word 'studies' is the most common ones, with 'safety' and 'data' receiving lower rankings. It is hence possible to hypothezise the following distiction:\n",
    "\n",
    "* Many negative and positive tend to be **argumentative** of why the given data does or does not show evidence of product safety. With safety concerns present, the authors tend to be more explicit in their wordings about 'data' and 'safety'\n",
    "* Neutral comments tend to be **descriptive** w.r.t. to the procedures followed during conducting and reporting the given study/studies\n",
    "\n",
    "This could prove to be an useful feature in one-vs-all classification approach. Obviously the dataset here is very limited, so the general applicability of these findings if of course questionable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "binding-strand",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['studies',\n",
       " 'safety',\n",
       " 'study',\n",
       " 'ct-p10',\n",
       " 'efficacy',\n",
       " 'data',\n",
       " 'patients',\n",
       " 'dose',\n",
       " 'insulin',\n",
       " 'product']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(top_ten['Neutral'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-appointment",
   "metadata": {},
   "source": [
    "### Bigram and trigram analysis\n",
    "\n",
    "A similar approach can be used for sequences of two and four words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "republican-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams, trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "usual-multimedia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive</th>\n",
       "      <th>Pos_rate</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neg_rate</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Neutr_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(safety, profile)</td>\n",
       "      <td>0.12500</td>\n",
       "      <td>(chmp, considers)</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>(insulin, glargine)</td>\n",
       "      <td>0.085714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(clinical, data)</td>\n",
       "      <td>0.06875</td>\n",
       "      <td>(considers, following)</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>(safety, profile)</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(ct-p10, mabthera)</td>\n",
       "      <td>0.05625</td>\n",
       "      <td>(following, measures)</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>(reference, products)</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(efficacy, data)</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>(necessary, address)</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>(safety, data)</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(reference, product)</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>(measures, necessary)</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>(pivotal, studies)</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(safety, data)</td>\n",
       "      <td>0.03750</td>\n",
       "      <td>(address, missing)</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>(et, al)</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(comparable, between)</td>\n",
       "      <td>0.03750</td>\n",
       "      <td>(address, issues)</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>(efficacy, safety)</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(between, ct-p10)</td>\n",
       "      <td>0.03750</td>\n",
       "      <td>(issues, related)</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>(medicinal, product)</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(bioequivalence, study)</td>\n",
       "      <td>0.03750</td>\n",
       "      <td>(although, dataset)</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>(overall, safety)</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(film-coated, tablets)</td>\n",
       "      <td>0.03750</td>\n",
       "      <td>(dataset, afl)</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>(profile, ct-p10)</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Positive  Pos_rate                Negative  Neg_rate  \\\n",
       "1         (safety, profile)   0.12500       (chmp, considers)  0.111111   \n",
       "2          (clinical, data)   0.06875  (considers, following)  0.111111   \n",
       "3        (ct-p10, mabthera)   0.05625   (following, measures)  0.111111   \n",
       "4          (efficacy, data)   0.04375    (necessary, address)  0.111111   \n",
       "5      (reference, product)   0.04375   (measures, necessary)  0.083333   \n",
       "6            (safety, data)   0.03750      (address, missing)  0.083333   \n",
       "7     (comparable, between)   0.03750       (address, issues)  0.083333   \n",
       "8         (between, ct-p10)   0.03750       (issues, related)  0.083333   \n",
       "9   (bioequivalence, study)   0.03750     (although, dataset)  0.083333   \n",
       "10   (film-coated, tablets)   0.03750          (dataset, afl)  0.083333   \n",
       "\n",
       "                  Neutral  Neutr_rate  \n",
       "1     (insulin, glargine)    0.085714  \n",
       "2       (safety, profile)    0.057143  \n",
       "3   (reference, products)    0.057143  \n",
       "4          (safety, data)    0.057143  \n",
       "5      (pivotal, studies)    0.057143  \n",
       "6                (et, al)    0.057143  \n",
       "7      (efficacy, safety)    0.057143  \n",
       "8    (medicinal, product)    0.042857  \n",
       "9       (overall, safety)    0.042857  \n",
       "10      (profile, ct-p10)    0.042857  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_fd_pos = FreqDist(list(bigrams(corp_pos)))\n",
    "bi_fd_neg = FreqDist(list(bigrams(corp_neg)))\n",
    "bi_fd_neutr = FreqDist(list(bigrams(corp_neutr)))\n",
    "\n",
    "top_ten_bi = pd.DataFrame({\n",
    "    'Positive': [w[0] for w in bi_fd_pos.most_common(10)],\n",
    "    'Pos_rate': [w[1] / len(data[data['Positive'] == 1]) for w in bi_fd_pos.most_common(10)],\n",
    "    'Negative': [w[0] for w in bi_fd_neg.most_common(10)],\n",
    "    'Neg_rate': [w[1] / len(data[data['Negative'] == 1]) for w in bi_fd_neg.most_common(10)],    \n",
    "    'Neutral': [w[0] for w in bi_fd_neutr.most_common(10)],\n",
    "    'Neutr_rate': [w[1] / len(data[data['Neutral'] == 1])for w in bi_fd_neutr.most_common(10)]\n",
    "}, index=range(1,11))\n",
    "\n",
    "top_ten_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "painful-running",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive</th>\n",
       "      <th>Pos_rate</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neg_rate</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Neutr_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(between, ct-p10, mabthera)</td>\n",
       "      <td>0.03750</td>\n",
       "      <td>(chmp, considers, following)</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>(overall, safety, profile)</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(based, efficacy, data)</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>(considers, following, measures)</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>(safety, profile, ct-p10)</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(data, considered, supportive)</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>(following, measures, necessary)</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>(profile, ct-p10, appeared)</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(mg, film-coated, tablets)</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>(measures, necessary, address)</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>(ct-p10, appeared, roughly)</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(2nd, line, treatment)</td>\n",
       "      <td>0.01875</td>\n",
       "      <td>(necessary, address, issues)</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>(appeared, roughly, similar)</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(biosimilarity, ct-p10, mabthera)</td>\n",
       "      <td>0.01875</td>\n",
       "      <td>(address, issues, related)</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>(roughly, similar, reference)</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(ct-p10, mabthera, considered)</td>\n",
       "      <td>0.01875</td>\n",
       "      <td>(although, dataset, afl)</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>(similar, reference, product)</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(mabthera, considered, demonstrated)</td>\n",
       "      <td>0.01875</td>\n",
       "      <td>(dataset, afl, patients)</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>(reference, product, although)</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(considered, demonstrated, based)</td>\n",
       "      <td>0.01875</td>\n",
       "      <td>(afl, patients, updated)</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>(product, although, pooled)</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(demonstrated, based, efficacy)</td>\n",
       "      <td>0.01875</td>\n",
       "      <td>(patients, updated, data)</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>(although, pooled, incidences)</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Positive  Pos_rate  \\\n",
       "1            (between, ct-p10, mabthera)   0.03750   \n",
       "2                (based, efficacy, data)   0.02500   \n",
       "3         (data, considered, supportive)   0.02500   \n",
       "4             (mg, film-coated, tablets)   0.02500   \n",
       "5                 (2nd, line, treatment)   0.01875   \n",
       "6      (biosimilarity, ct-p10, mabthera)   0.01875   \n",
       "7         (ct-p10, mabthera, considered)   0.01875   \n",
       "8   (mabthera, considered, demonstrated)   0.01875   \n",
       "9      (considered, demonstrated, based)   0.01875   \n",
       "10       (demonstrated, based, efficacy)   0.01875   \n",
       "\n",
       "                            Negative  Neg_rate  \\\n",
       "1       (chmp, considers, following)  0.111111   \n",
       "2   (considers, following, measures)  0.111111   \n",
       "3   (following, measures, necessary)  0.083333   \n",
       "4     (measures, necessary, address)  0.083333   \n",
       "5       (necessary, address, issues)  0.083333   \n",
       "6         (address, issues, related)  0.083333   \n",
       "7           (although, dataset, afl)  0.083333   \n",
       "8           (dataset, afl, patients)  0.083333   \n",
       "9           (afl, patients, updated)  0.083333   \n",
       "10         (patients, updated, data)  0.083333   \n",
       "\n",
       "                           Neutral  Neutr_rate  \n",
       "1       (overall, safety, profile)    0.042857  \n",
       "2        (safety, profile, ct-p10)    0.042857  \n",
       "3      (profile, ct-p10, appeared)    0.042857  \n",
       "4      (ct-p10, appeared, roughly)    0.042857  \n",
       "5     (appeared, roughly, similar)    0.042857  \n",
       "6    (roughly, similar, reference)    0.042857  \n",
       "7    (similar, reference, product)    0.042857  \n",
       "8   (reference, product, although)    0.042857  \n",
       "9      (product, although, pooled)    0.042857  \n",
       "10  (although, pooled, incidences)    0.042857  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_fd_pos = FreqDist(list(trigrams(corp_pos)))\n",
    "tri_fd_neg = FreqDist(list(trigrams(corp_neg)))\n",
    "tri_fd_neutr = FreqDist(list(trigrams(corp_neutr)))\n",
    "\n",
    "top_ten_tri = pd.DataFrame({\n",
    "    'Positive': [w[0] for w in tri_fd_pos.most_common(10)],\n",
    "    'Pos_rate': [w[1] / len(data[data['Positive'] == 1]) for w in tri_fd_pos.most_common(10)],\n",
    "    'Negative': [w[0] for w in tri_fd_neg.most_common(10)],\n",
    "    'Neg_rate': [w[1] / len(data[data['Negative'] == 1]) for w in tri_fd_neg.most_common(10)],    \n",
    "    'Neutral': [w[0] for w in tri_fd_neutr.most_common(10)],\n",
    "    'Neutr_rate': [w[1] / len(data[data['Neutral'] == 1])for w in tri_fd_neutr.most_common(10)]\n",
    "}, index=range(1,11))\n",
    "\n",
    "top_ten_tri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-invalid",
   "metadata": {},
   "source": [
    "From these analyses it can be determined that there seem to be some phrases the evaluators frequently use word-for-word when describing limitations in the drug evaluation procedure. For instance, the phrase\n",
    "\n",
    "```chmp considers following measures```\n",
    "\n",
    "appears a total of four times (11 %) in the negative class, but not one single time in the positive class. \n",
    "\n",
    "From statistical point of view the dataset is probably too small to efficiently train on trigram-based features. Bigram features could offer some useful information, since at least the phrases 'safety profile' and 'clinical data' ore replicated in non-negligiable portion of Positive examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-wright",
   "metadata": {},
   "source": [
    "### TODO migrate this to somewhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "organizational-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "determined-literature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "        [0, 1, 0, 1, 0, 2, 1, 0, 1],\n",
       "        [1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
       "        [0, 1, 1, 1, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "according-tackle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 8,\n",
       " 'is': 3,\n",
       " 'the': 6,\n",
       " 'first': 2,\n",
       " 'document': 1,\n",
       " 'second': 5,\n",
       " 'and': 0,\n",
       " 'third': 7,\n",
       " 'one': 4}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-decline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
